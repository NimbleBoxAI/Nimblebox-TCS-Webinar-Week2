{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RiWOqVGJpnR5",
    "outputId": "fdde8e36-e354-4943-d027-e8a691e184ec"
   },
   "source": [
    "# Introduction to Deep Learning - I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJQgCx-EpnRm"
   },
   "source": [
    "Created by [Nimblebox Inc.](https://www.nimblebox.ai/).\n",
    "\n",
    "<img style=\"float:left; margin-left: 50px\" src=\"https://miro.medium.com/max/448/1*jYc7Hq9dU4kHXqm_Yd6vmw.png\" alt=\"Numpy Logo\" width=\"300\" height=\"400\">\n",
    "\n",
    "<img style=\"float:right; margin-right: 50px\" src=\"https://media-exp1.licdn.com/dms/image/C4E1BAQH3ErUUfLXoHQ/company-background_10000/0?e=2159024400&v=beta&t=9Z2hcX4LqsxlDd2BAAW8xDc-Obfvk_rziT1AkPKBcCc\" alt=\"Nimblebox Logo\" width=\"500\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pobAbXhxpnRm"
   },
   "source": [
    "## Introduction:  \n",
    "\n",
    "Till now we looked at Traditional Statistical Machine Learning models like Support Vector Machines, different Linear and Logistic Models, Random Forests, etc.\n",
    "\n",
    "As we have seen, Machine Learning is set of algorithms that parse data, learn from them, and then apply what they’ve learned to make intelligent decisions. Whereas, Deep Learning achieves great power and flexibility by learning to represent the world as nested hierarchy of concepts, with each concept defined in relation to simpler concepts, and more abstract representations computed in terms of less abstract ones.\n",
    "\n",
    "<div style=\"text-align: center\"><img src=\"https://i2.wp.com/semiengineering.com/wp-content/uploads/2018/01/MLvsDL.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Deep Learning?\n",
    "\n",
    "Deep learning–a machine learning technique–is an efficient way of learning that relies on big data, where features that can help a machine map an input to an output is automatically extracted from layers of “neurons”. A neural network is a type of deep learning architecture and in this webinar, we will be focusing on a simple Aritficial Neural Network.\n",
    "\n",
    "### What is Neural Network?\n",
    "\n",
    "Neural networks are composed of simple building blocks called neurons. A neuron is a mathematical function that takes data as input, performs a transformation on them, and produces an output. This means that neurons can represent any mathematical function; however, in neural networks, we typically use non-linear functions.\n",
    "\n",
    "<figure style=\"text-align: center\"><img src=\"https://miro.medium.com/max/702/1*NZc0TcMCzpgVZXvUdEkqvA.png\" width=\"400\" height=\"500\"><figcaption>A single neuron in a network</figcaption></figure>\n",
    "\n",
    "Looking at the neuron above, you can see that it’s composed of two main parts: the summation and the activation function. A neuron takes data (x₁, x₂, x₃) as input, multiplies each with a specific weight (w₁, w₂, w₃), and then passes the result to a nonlinear function called the activation function to produce an output.\n",
    "\n",
    "A neural network combines multiple neurons by stacking them vertically/horizontally to create a network of neurons-hence the name “neural network”. A simple one-neuron network is called a perceptron and is the simplest network ever.\n",
    "\n",
    "### Layers of Neural Network\n",
    "\n",
    "1. The first layer is called the input layer, and the number of nodes will depend on the number of features present in your dataset.\n",
    "2. The final layer of the neural network is called the output layer, and the number depends on what you’re trying to predict. For regression and binary classification tasks, you can use a single node; while for multi-class problems, you’ll use multiple nodes, depending on the number of classes.\n",
    "3. The layers between the input and the final layer is where the magic happens— these are called the hidden layers. The hidden layers can be as deep or wide as you want, and while a deeper network is better, the computational time also increases as you go deeper.\n",
    "\n",
    "<div style=\"text-align: center\"><img src=\"https://miro.medium.com/max/702/1*Z3zHoX1nhK6Rsmd4yNPdsg.jpeg\" width=\"500\" height=\"600\"></div>\n",
    "\n",
    "### Weights and Bias\n",
    "\n",
    "Weights and biases are the learnable parameters that help a neural network correctly learn a function. Think of weights as a measure of how sure you are that a feature contributes to a prediction and the bias as a base value that your predictions must start from.\n",
    "\n",
    "A machine learning model uses lots of examples to learn the correct weights and bias to assign to each feature in a dataset to help it correctly predict outputs.\n",
    "\n",
    "### Activation Function\n",
    "\n",
    "Activations are the nonlinear computations done in each node of a Neural Network. There are many types of activation functions used in deep learning - some popular ones are Sigmoid, ReLU, tanh, Leaky ReLU, and so on.\n",
    "\n",
    "<div style=\"text-align: center\"><img src=\"https://miro.medium.com/max/702/1*ZafDv3VUm60Eh10OeJu1vw.png\" width=\"600\" height=\"700\"></div>\n",
    "\n",
    "The hidden layer receives values from the previous layer, calculates a weighted sum, adds the bias term, and then passes each result through an activation function and continues till it reaches the last but one hidden layer. The result from this last but one layer is then passed to the output layer, where another weighted sum is performed using the second weights and biases. But then instead of passing the result through another activation function, it is passed through an output activation function.\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "The loss function is a way of measuring how good a model’s prediction is so that it can adjust the weights and biases. A loss function must be properly designed so that it can correctly penalize a model that is wrong and reward a model that is right. This means that you want the loss to tell you if a prediction made is far or close to the true prediction. The choice of the loss function is dependent on the task—and for classification problems, you can use cross-entropy loss.\n",
    "\n",
    "$$CE = -\\sum_{i}^{C} y_i log(\\hat y_i)$$\n",
    "\n",
    "here $C$ is the number of classes, $y_i$ is the true value and $\\hat y_i$ is the predicted value\n",
    "\n",
    "### Forward Propagation\n",
    "\n",
    "Forward propagation is the name given to the series of computations performed by the neural network before a prediction is made. In a two-layer network, it will perform the following computation for forward propagation:\n",
    "\n",
    "1. Compute the weighted sum between the input and the first layer's weights and then add the bias: **Z1 = (W1 * X) + b**\n",
    "2. Pass the result through the ReLU activation function: **A1 = ReLU(Z1)**\n",
    "3. Compute the weighted sum between the output (A1) of the previous step and the second layer's weights—also add the bias: **Z2 = (W2 * A1) + b2**\n",
    "4. Compute the output function by passing the result through a sigmoid function: **A2 = sigmoid(Z2)**\n",
    "5. And finally, compute the loss between the predicted output and the true labels: **loss(A2, Y)**\n",
    "\n",
    "Note: For a three-layer neural network, you’d have to compute Z3 and A2 using W3 and b3 before the output layer.\n",
    "\n",
    "### Backpropogation\n",
    "\n",
    "Backpropagation is the name given to the process of training a neural network by updating its weights and bias.\n",
    "\n",
    "A neural network learns to predict the correct values by continuously trying different values for the weights and then comparing the losses. If the loss function decreases, then the current weight is better than the previous, or vice versa. This means that the neural net has to go through many training (forward propagation) and update (backpropagation) cycles in order to get the best weights and biases. This cycle is what we generally refer to as the training phase, and the process of searching for the right weights is called optimization.\n",
    "\n",
    "The way we do this by using chain rule to find the local gradient with respect to each input.\n",
    "\n",
    "This is very big and vast topic, thus I will recommend you to go throught this [original paper on the topic](https://page.mi.fu-berlin.de/rojas/neural/chapter/K7.pdf) or watch different tutorials to clear this concept.\n",
    "\n",
    "### Training Neural Networks\n",
    "\n",
    "To automatically use this information to update the weights and biases, a neural network must perform hundreds, thousands, and even millions of forward and backward propagations. That is, in the training phase, the neural network must perform the following:\n",
    "1. Forward propagation\n",
    "2. Backpropagation\n",
    "3. Weight updates with calculated gradients\n",
    "4. Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using Keras to create a simple Dense Neural Network to classify digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Downloading Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6852581910>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_index = 7777 # You may select anything up to 60,000\n",
    "\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Reshaping and Normalizing the Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 784)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Flatten the images.\n",
    "x_train = x_train.reshape((-1, 784))\n",
    "x_test = x_test.reshape((-1, 784))\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Building the Convolutional Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=tf.nn.relu, input_shape=(784,)))\n",
    "model.add(Dense(64, activation=tf.nn.relu))\n",
    "model.add(Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Compiling and Fitting the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2246 - accuracy: 0.9349\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2090 - accuracy: 0.9403\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1946 - accuracy: 0.9434\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1829 - accuracy: 0.9462\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.1715 - accuracy: 0.9492\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.1613 - accuracy: 0.9520\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1524 - accuracy: 0.9550\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1450 - accuracy: 0.9566\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1368 - accuracy: 0.9587\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1305 - accuracy: 0.9609\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1240 - accuracy: 0.9629\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1183 - accuracy: 0.9645\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1128 - accuracy: 0.9662\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.1088 - accuracy: 0.9672\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1035 - accuracy: 0.9693\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0998 - accuracy: 0.9701\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0960 - accuracy: 0.9712\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0927 - accuracy: 0.9724\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0900 - accuracy: 0.9730\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0866 - accuracy: 0.9740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6828740430>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Evaluating the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1163 - accuracy: 0.9658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11626086384057999, 0.9657999873161316]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/saurabh/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /home/saurabh/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/saurabh/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/saurabh/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/saurabh/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /home/saurabh/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:885 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /home/saurabh/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_4 is incompatible with the layer: expected axis -1 of input shape to have value 784 but received input with shape [None, 28, 28, 1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b5ee7909c22f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9999\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted Number:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 505\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    506\u001b[0m             *args, **kwds))\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/saurabh/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /home/saurabh/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/saurabh/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/saurabh/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/saurabh/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /home/saurabh/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:885 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /home/saurabh/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_4 is incompatible with the layer: expected axis -1 of input shape to have value 784 but received input with shape [None, 28, 28, 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 9999\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(\"Predicted Number:\", pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
